{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections.abc import Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import xarray as xr\n",
    "from bonner.caching import cache\n",
    "from bonner.computation.metrics import pearson_r, spearman_r\n",
    "from bonner.plotting import DEFAULT_MATPLOTLIBRC, save_figure\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from lib.datasets import (\n",
    "    compute_shared_stimuli,\n",
    "    filter_by_stimulus,\n",
    "    nsd,\n",
    "    split_by_repetition,\n",
    ")\n",
    "from lib.spectra import CrossDecomposition\n",
    "from lib.utilities import MANUSCRIPT_HOME\n",
    "\n",
    "FIGURES_HOME = MANUSCRIPT_HOME / \"figures\"\n",
    "\n",
    "sns.set_theme(context=\"paper\", style=\"ticks\", rc=DEFAULT_MATPLOTLIBRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsm(x: torch.Tensor) -> torch.Tensor:\n",
    "    return pearson_r(\n",
    "        x.transpose(-2, -1),\n",
    "        correction=0,\n",
    "        return_diagonal=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_upper_triangle(rsm: torch.Tensor) -> torch.Tensor:\n",
    "    x_indices, y_indices = torch.triu_indices(rsm.shape[-1], rsm.shape[-1], offset=1)\n",
    "    return rsm[..., x_indices, y_indices]\n",
    "\n",
    "\n",
    "def convert_dataarray_to_tensor(x: xr.DataArray) -> torch.Tensor:\n",
    "    return torch.from_numpy(x.to_numpy()).to(dtype=torch.float64)\n",
    "\n",
    "\n",
    "def _get_correlation_function(correlation: str) -> Callable:\n",
    "    match correlation:\n",
    "        case \"Pearson\":\n",
    "            func = pearson_r\n",
    "        case \"Spearman\":\n",
    "            func = spearman_r\n",
    "        case _:\n",
    "            raise ValueError\n",
    "    return func\n",
    "\n",
    "\n",
    "def reconstruct_data(x: xr.DataArray, /, *, n: int) -> xr.DataArray:\n",
    "    cross_decomposition = CrossDecomposition(randomized=True)\n",
    "    cross_decomposition.fit(x, x)\n",
    "    x_transformed = cross_decomposition.transform(x, direction=\"right\")\n",
    "\n",
    "    return cross_decomposition.inverse_transform(\n",
    "        x_transformed,\n",
    "        direction=\"right\",\n",
    "        components=n,\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_rsa_correlation(\n",
    "    rsm_x: torch.Tensor,\n",
    "    rsm_y: torch.Tensor,\n",
    "    /,\n",
    "    *,\n",
    "    correlation: str,\n",
    "    n_bootstraps: int = 5_000,\n",
    "    subsample_fraction: float = 0.9,\n",
    "    seed: int = 0,\n",
    "    batch_size: int = 500,\n",
    ") -> tuple[float, torch.Tensor]:\n",
    "    func = _get_correlation_function(correlation)\n",
    "\n",
    "    n_stimuli = rsm_x.shape[-1]\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    r_bootstrapped = []\n",
    "\n",
    "    for bootstrap_indices in tqdm(\n",
    "        itertools.batched(range(n_bootstraps), n=batch_size),\n",
    "        desc=\"bootstrap\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        rsms_x, rsms_y = [], []\n",
    "        for _ in bootstrap_indices:\n",
    "            samples = rng.permutation(n_stimuli)[: int(subsample_fraction * n_stimuli)]\n",
    "            rsms_x.append(rsm_x[samples, :][:, samples])\n",
    "            rsms_y.append(rsm_y[samples, :][:, samples])\n",
    "\n",
    "        r_bootstrapped.append(\n",
    "            func(\n",
    "                extract_upper_triangle(torch.stack(rsms_x)).T,\n",
    "                extract_upper_triangle(torch.stack(rsms_y)).T,\n",
    "                return_diagonal=True,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    r = float(\n",
    "        func(\n",
    "            extract_upper_triangle(rsm_x),\n",
    "            extract_upper_triangle(rsm_y),\n",
    "        ),\n",
    "    )\n",
    "    return r, torch.concatenate(r_bootstrapped)\n",
    "\n",
    "\n",
    "def clean_rsm(rsm: torch.Tensor, /, *, indices: np.ndarray) -> np.ndarray:\n",
    "    rsm = rsm[indices, :][:, indices]\n",
    "    rsm = torch.triu(rsm, diagonal=1)\n",
    "    rsm[rsm == 0] = torch.nan\n",
    "    return rsm.cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_all_pairwise_rsa_correlations(\n",
    "    rsms: dict[str, dict[int, dict[int, torch.Tensor]]],\n",
    ") -> pd.DataFrame:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    rows = []\n",
    "    for metric in (\"Pearson\", \"Spearman\"):\n",
    "        prefix = f\"figures/rsa_correlations/metric={metric}\"\n",
    "        for subject_1, subject_2 in itertools.product(range(nsd.N_SUBJECTS), repeat=2):\n",
    "            cacher = cache(f\"{prefix}/high-D-high-D-S{subject_1}T0-S{subject_2}T1.pkl\")\n",
    "            mean_1, bootstrap_1 = cacher(compute_rsa_correlation)(\n",
    "                rsms[\"high-D\"][subject_1][0].to(device),\n",
    "                rsms[\"high-D\"][subject_2][1].to(device),\n",
    "                correlation=metric,\n",
    "            )\n",
    "            cacher = cache(f\"{prefix}/high-D-low-D-S{subject_1}T0-S{subject_2}T1.pkl\")\n",
    "            mean_2, bootstrap_2 = cacher(compute_rsa_correlation)(\n",
    "                rsms[\"high-D\"][subject_1][0].to(device),\n",
    "                rsms[\"low-D\"][subject_2][1].to(device),\n",
    "                correlation=metric,\n",
    "            )\n",
    "            cacher = cache(f\"{prefix}/low-D-high-D-S{subject_1}T0-S{subject_2}T1.pkl\")\n",
    "            mean_3, bootstrap_3 = cacher(compute_rsa_correlation)(\n",
    "                rsms[\"low-D\"][subject_1][0].to(device),\n",
    "                rsms[\"high-D\"][subject_2][1].to(device),\n",
    "                correlation=metric,\n",
    "            )\n",
    "            cacher = cache(f\"{prefix}/low-D-low-D-S{subject_1}T0-S{subject_2}T1.pkl\")\n",
    "            mean_4, bootstrap_4 = cacher(compute_rsa_correlation)(\n",
    "                rsms[\"low-D\"][subject_1][0].to(device),\n",
    "                rsms[\"low-D\"][subject_2][1].to(device),\n",
    "                correlation=metric,\n",
    "            )\n",
    "            means = torch.Tensor(\n",
    "                [\n",
    "                    mean_1,\n",
    "                    mean_2,\n",
    "                    mean_3,\n",
    "                    mean_4,\n",
    "                    (mean_2 + mean_3) / 2,\n",
    "                ],\n",
    "            )\n",
    "            bootstraps = torch.stack(\n",
    "                [\n",
    "                    bootstrap_1,\n",
    "                    bootstrap_2,\n",
    "                    bootstrap_3,\n",
    "                    bootstrap_4,\n",
    "                    torch.stack([bootstrap_2, bootstrap_3]).mean(dim=0),\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            rows.append(\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"mean\": means.tolist(),\n",
    "                        \"std\": bootstraps.std(dim=-1).tolist(),\n",
    "                        \"0.025\": torch.quantile(bootstraps, q=0.025, dim=-1).tolist(),\n",
    "                        \"0.975\": torch.quantile(bootstraps, q=0.975, dim=-1).tolist(),\n",
    "                        \"comparison\": [\n",
    "                            \"high-D vs high-D\",\n",
    "                            \"high-D vs low-D\",\n",
    "                            \"low-D vs high-D\",\n",
    "                            \"low-D vs low-D\",\n",
    "                            \"mean\",\n",
    "                        ],\n",
    "                    },\n",
    "                ).assign(\n",
    "                    **{\n",
    "                        \"subject (trial 1)\": subject_1,\n",
    "                        \"subject (trial 2)\": subject_2,\n",
    "                        \"metric\": metric,\n",
    "                    },\n",
    "                ),\n",
    "            )\n",
    "    return pd.concat(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PCS = 10\n",
    "\n",
    "datasets = {\n",
    "    subject: nsd.load_dataset(subject=subject) for subject in range(nsd.N_SUBJECTS)\n",
    "}\n",
    "\n",
    "shared_stimuli = compute_shared_stimuli(datasets.values(), n_repetitions=2)\n",
    "\n",
    "datasets = {\n",
    "    subject: split_by_repetition(\n",
    "        filter_by_stimulus(dataset, stimuli=shared_stimuli),\n",
    "        n_repetitions=2,\n",
    "    )\n",
    "    for subject, dataset in datasets.items()\n",
    "}\n",
    "\n",
    "rsms = {\n",
    "    \"high-D\": {\n",
    "        subject: {\n",
    "            repetition: compute_rsm(\n",
    "                convert_dataarray_to_tensor(datasets[subject][repetition]),\n",
    "            )\n",
    "            for repetition in (0, 1)\n",
    "        }\n",
    "        for subject in range(nsd.N_SUBJECTS)\n",
    "    },\n",
    "    \"low-D\": {\n",
    "        subject: {\n",
    "            repetition: compute_rsm(\n",
    "                convert_dataarray_to_tensor(\n",
    "                    reconstruct_data(datasets[subject][repetition], n=N_PCS),\n",
    "                ),\n",
    "            )\n",
    "            for repetition in (0, 1)\n",
    "        }\n",
    "        for subject in range(nsd.N_SUBJECTS)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_decomposition = CrossDecomposition(randomized=True)\n",
    "cross_decomposition.fit(datasets[0][0], datasets[1][1])\n",
    "transformed = cross_decomposition.transform(datasets[0][0], direction=\"left\")[\n",
    "    :,\n",
    "    0,\n",
    "].to_numpy()\n",
    "indices = np.argsort(transformed)\n",
    "\n",
    "kwargs_shared = {\n",
    "    \"cmap\": \"RdBu_r\",\n",
    "    \"rasterized\": True,\n",
    "}\n",
    "\n",
    "kwargs_full = {\n",
    "    \"vmin\": -0.1,\n",
    "    \"vmax\": 0.1,\n",
    "} | kwargs_shared\n",
    "\n",
    "kwargs_reconstructed = {\n",
    "    \"vmin\": -0.46,\n",
    "    \"vmax\": 0.46,\n",
    "} | kwargs_shared\n",
    "\n",
    "fig = plt.figure(figsize=(4.5, 6.5))\n",
    "axes = fig.subplot_mosaic(\n",
    "    \"\"\"\n",
    "    ABG\n",
    "    ABE\n",
    "    ABE\n",
    "    ABH\n",
    "    CDI\n",
    "    CDF\n",
    "    CDF\n",
    "    CDJ\n",
    "    KKK\n",
    "    \"\"\",\n",
    "    width_ratios=[20, 20, 1],\n",
    "    height_ratios=[1, 50, 50, 1, 1, 50, 50, 1, 127.5],\n",
    ")\n",
    "\n",
    "images = {\n",
    "    \"A\": axes[\"A\"].imshow(\n",
    "        clean_rsm(rsms[\"high-D\"][0][0], indices=indices),\n",
    "        **kwargs_full,\n",
    "    ),\n",
    "    \"B\": axes[\"B\"].imshow(\n",
    "        clean_rsm(rsms[\"high-D\"][1][1], indices=indices),\n",
    "        **kwargs_full,\n",
    "    ),\n",
    "    \"C\": axes[\"C\"].imshow(\n",
    "        clean_rsm(rsms[\"low-D\"][0][0], indices=indices),\n",
    "        **kwargs_reconstructed,\n",
    "    ),\n",
    "    \"D\": axes[\"D\"].imshow(\n",
    "        clean_rsm(rsms[\"low-D\"][1][1], indices=indices),\n",
    "        **kwargs_reconstructed,\n",
    "    ),\n",
    "}\n",
    "for image in images.values():\n",
    "    image.set_rasterized(True)\n",
    "\n",
    "for key, ax in axes.items():\n",
    "    if key != \"K\":\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "axes[\"A\"].set_ylabel(\"high-D\")\n",
    "axes[\"A\"].set_title(\"subject 1\", pad=23)\n",
    "axes[\"B\"].set_title(\"subject 2\", pad=23)\n",
    "axes[\"C\"].set_ylabel(\"low-D\")\n",
    "\n",
    "kwargs = {\n",
    "    \"c\": \"gray\",\n",
    "    \"transform\": axes[\"A\"].transAxes,\n",
    "    # \"ha\": \"center\",\n",
    "    # \"va\": \"baseline\",\n",
    "    \"fontsize\": \"x-small\",\n",
    "    \"style\": \"italic\",\n",
    "}\n",
    "axes[\"A\"].text(\n",
    "    0.5,\n",
    "    1.05,\n",
    "    \"766 stimuli\",\n",
    "    ha=\"center\",\n",
    "    va=\"baseline\",\n",
    "    **kwargs,\n",
    ")\n",
    "axes[\"A\"].text(\n",
    "    1.025,\n",
    "    0.5,\n",
    "    \"766 stimuli\",\n",
    "    rotation=270,\n",
    "    ha=\"left\",\n",
    "    va=\"center\",\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "cax = axes[\"E\"]\n",
    "cb = fig.colorbar(mappable=images[\"B\"], cax=cax, use_gridspec=True)\n",
    "cb.outline.set_visible(False)\n",
    "cax.tick_params(length=0, labelleft=True, labelright=False)\n",
    "cb.set_ticks([-0.1, 0, 0.1])\n",
    "\n",
    "cax = axes[\"F\"]\n",
    "cb = fig.colorbar(mappable=images[\"D\"], cax=cax, use_gridspec=True)\n",
    "cb.outline.set_visible(False)\n",
    "cax.tick_params(length=0, labelleft=True, labelright=False)\n",
    "cb.set_ticks([-0.4, 0, 0.4])\n",
    "\n",
    "axes[\"G\"].set_title(\"Pearson\\ncorrelation\")\n",
    "\n",
    "ax = axes[\"K\"]\n",
    "palette = sns.color_palette(\"Purples_r\", n_colors=40)\n",
    "average_cross_comparisons = True\n",
    "\n",
    "output = compute_all_pairwise_rsa_correlations(rsms=rsms)\n",
    "\n",
    "output_ = output.loc[\n",
    "    (output[\"subject (trial 1)\"] == 0) & (output[\"subject (trial 2)\"] == 1)\n",
    "]\n",
    "if average_cross_comparisons:\n",
    "    arrow_width = 4.75\n",
    "    output_ = output_.loc[\n",
    "        np.isin(output_[\"comparison\"], [\"high-D vs high-D\", \"low-D vs low-D\", \"mean\"])\n",
    "    ]\n",
    "    output_ = output_.iloc[[0, 2, 1, 3, 5, 4], :]\n",
    "    palette = [\n",
    "        palette[5],\n",
    "        palette[15],\n",
    "        palette[-15],\n",
    "        palette[5],\n",
    "        palette[15],\n",
    "        palette[-15],\n",
    "    ]\n",
    "    output_[\"comparison\"] = output_[\"comparison\"].replace(\"mean\", \"high-D vs low-D\")\n",
    "else:\n",
    "    arrow_width = 5\n",
    "    output_ = output_.loc[output_[\"comparison\"] != \"mean\"]\n",
    "    palette = [\n",
    "        palette[5],\n",
    "        palette[14],\n",
    "        palette[16],\n",
    "        palette[-15],\n",
    "        palette[5],\n",
    "        palette[14],\n",
    "        palette[16],\n",
    "        palette[-15],\n",
    "    ]\n",
    "\n",
    "n_points = len(output_)\n",
    "n_groups = 2\n",
    "n_points_per_group = n_points // n_groups\n",
    "\n",
    "std_factor = 2\n",
    "\n",
    "x = list(range(n_points))\n",
    "for i_point, (x_, y, low, high) in enumerate(\n",
    "    zip(\n",
    "        x,\n",
    "        output_[\"mean\"].to_numpy(),\n",
    "        output_[\"0.025\"].to_numpy(),\n",
    "        output_[\"0.975\"].to_numpy(),\n",
    "        strict=False,\n",
    "    ),\n",
    "):\n",
    "    ax.errorbar(\n",
    "        x_,\n",
    "        y,\n",
    "        std_factor * np.array([y - low, high - y]).reshape((2, 1)),\n",
    "        ls=\"None\",\n",
    "        c=palette[i_point],\n",
    "        marker=\"o\",\n",
    "        barsabove=True,\n",
    "    )\n",
    "\n",
    "kwargs = {\n",
    "    \"ha\": \"center\",\n",
    "    \"va\": \"center\",\n",
    "    \"arrowprops\": {\n",
    "        \"arrowstyle\": f\"-[, widthB={arrow_width}, lengthB=0.5\",\n",
    "        \"lw\": 1.0,\n",
    "        \"color\": \"dimgray\",\n",
    "    },\n",
    "    \"c\": \"dimgray\",\n",
    "    \"fontsize\": \"small\",\n",
    "}\n",
    "x_ = (n_points_per_group - 1) / 2\n",
    "ax.annotate(\"Pearson\\n(linear)\", xy=(x_, 0.14), xytext=(x_, 0.07), **kwargs)\n",
    "\n",
    "x_ = n_points_per_group + (n_points_per_group - 1) / 2\n",
    "ax.annotate(\"Spearman\\n(rank-order)\", xy=(x_, 0.14), xytext=(x_, 0.07), **kwargs)\n",
    "\n",
    "xticklabels = output_[\"comparison\"].to_list()\n",
    "ax.set_xticks(x, xticklabels, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.set_ylim(bottom=0, top=0.3)\n",
    "ax.set_xlim(left=-1, right=n_points)\n",
    "ax.set_ylabel(\"RSA correlation\")\n",
    "\n",
    "fig.suptitle(\"representational similarity matrices (RSMs)\", x=0.5, y=1)\n",
    "\n",
    "save_figure(\n",
    "    fig,\n",
    "    filepath=FIGURES_HOME / \"rsa.pdf\",\n",
    "    dpi=300,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-dimensionality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
